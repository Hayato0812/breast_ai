{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def gaussian_noise(x_data,y_label):\n",
    "  new_x = []\n",
    "  new_y = []\n",
    "  for i in range(len(x_data)):\n",
    "\n",
    "    row, col, ch = 150,150,3\n",
    "    mean = 0\n",
    "    sigma = 15\n",
    "  \n",
    "    gauss = np.random.normal(mean, sigma,(row,col,ch))\n",
    "    gauss = gauss.reshape(row,col, ch)\n",
    "    gauss_img = x_data[i] + gauss\n",
    "    new_x.append(gauss_img)\n",
    "    new_y.append(y_label[i])\n",
    "  return new_x, new_y\n",
    "   \n",
    "def pepper_noise(x_data,y_label):\n",
    "  \n",
    "  new_x = []\n",
    "  new_y = []\n",
    "  for i in range(len(x_data)):\n",
    "\n",
    "    row, col,ch = 150,150,3\n",
    "    s_vs_p = 0.5\n",
    "    amount = 0.004\n",
    "    sp_img = x_data[i].copy()\n",
    "\n",
    "    num_pepper = np.ceil(amount* 67500 * (1. - s_vs_p))\n",
    "    coords = [np.random.randint(0, i-1 , int(num_pepper)) for i in (150,150,3)]\n",
    "    sp_img[coords[:-1]] = (0,0,0)\n",
    "    new_x.append(sp_img)\n",
    "    new_y.append(y_label[i])\n",
    "\n",
    "  return new_x,new_y\n",
    "\n",
    "\n",
    "def salt_noise(x_data,y_label):\n",
    "\n",
    "  new_x = []\n",
    "  new_y = []\n",
    "  for i in range(len(x_data)):\n",
    "\n",
    "    row,col,ch = 150,150,3\n",
    "    s_vs_p = 0.5\n",
    "    amount = 0.004\n",
    "    sp_img = x_data[i].copy()\n",
    "\n",
    "\n",
    "    num_salt = np.ceil(amount * 67500 * s_vs_p)\n",
    "    coords = [np.random.randint(0, i-1 , int(num_salt)) for i in (150,150,3)]\n",
    "    sp_img[coords[:-1]] = (255,255,255)\n",
    "    new_x.append(sp_img)\n",
    "    new_y.append(y_label[i])\n",
    "  return new_x,new_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "def plot_graph(history,epoch):  \n",
    "  plt.plot(np.arange(epoch)+1, history['mean_absolute_error'], label='mae')\n",
    "  plt.plot(np.arange(epoch)+1, history['val_mean_absolute_error'],label='val_mae')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.title('mae and val_mae in breast_ai')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  \n",
    "   \n",
    "  plt.plot(np.arange(epoch)+1, history['loss'], label='loss')\n",
    "  plt.plot(np.arange(epoch)+1, history['val_loss'],label='val_loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.title('loss and val_loss in breast_ai')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/hayatoyamaguchi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'augmentation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9fc87da70567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_learningcurve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'augmentation'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# import augmentation\n",
    "from tqdm import tqdm\n",
    "# import plot_learningcurve\n",
    "\n",
    "os.environ['OPENCV_IO_ENABLE_JASPER']= '1'\n",
    "#数値に変換\n",
    "def trans_from_cup_to_int(name_value):\n",
    "    name_array = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H以上\"]\n",
    "    return name_array.index(name_value)\n",
    "\n",
    "#データの読み込み\n",
    "def load_data():\n",
    "    print(\"start loading...\")\n",
    "    path = \"data\"\n",
    "    name_list = [i for i in os.listdir(path) if i != '.DS_Store']\n",
    "    pic_num = 0\n",
    "    x_data = []\n",
    "    y_label_data = []\n",
    "    for name in name_list:\n",
    "        label_value = trans_from_cup_to_int(name)\n",
    "        pic_folder_path = path + \"/\" + name\n",
    "        pic_list = [i for i in os.listdir(pic_folder_path) if i != '.DS_Store']\n",
    "        for pic_name in tqdm(pic_list):\n",
    "            pic_path = pic_folder_path+\"/\"+pic_name\n",
    "            img = cv2.imread(pic_path)\n",
    "            x_data.append(img)\n",
    "            y_label_data.append(label_value)\n",
    "    x_data = np.array(x_data)\n",
    "    y_label_data = np.array(y_label_data)\n",
    "    print(\"loading has finished!\")\n",
    "    return x_data, y_label_data\n",
    "\n",
    "#データの大きさ揃える、とりあえず150*150で様子見\n",
    "def resize_picture(images):\n",
    "    changed_images = []\n",
    "    for img in images:\n",
    "        img = cv2.resize(img, dsize=(150, 150))\n",
    "        changed_images.append(img)\n",
    "    changed_images = np.array(changed_images)\n",
    "    return changed_images\n",
    "\n",
    "#データの切り取りによるかさまし、いらないかも\n",
    "def make_more_data(images):\n",
    "    trans_images = []\n",
    "    for image in images:\n",
    "        cut_img = img[img.shape[0]//6:img.shape[0]*5//6,img.shape[1]//6:img.shape[1]*5//6]\n",
    "        trans_images.append(cut_img)\n",
    "    images.extend(trans_images)\n",
    "    return images\n",
    "\n",
    "def build_model():\n",
    "    base_model=VGG19(weights='imagenet',include_top=False,\n",
    "                 input_tensor=Input(shape=(150,150,3)))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(30))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(30))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model = Model(input=base_model.input,output=model(base_model.output))    \n",
    "\n",
    "    for layer in base_model.layers[:15]:\n",
    "        layer.trainable=False\n",
    "\n",
    "    model.compile(Adam(lr=0.001),loss='mean_squared_error',metrics=['mae'])\n",
    "    print(\"Build model!\")\n",
    "    return model\n",
    "'''\n",
    "\n",
    "def fit_model(model):\n",
    "    samples_per_epoch = 20\n",
    "    batch_size=32\n",
    "    epochs = 10\n",
    "    #とりあえずぼかし以外\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    #ここから下はこれを参照https://lp-tech.net/articles/Y56uo\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10 , verbose=1)\n",
    "#     checkpointer = ModelCheckpoint(\n",
    "#         model_weights,\n",
    "#         monitor='val_loss',\n",
    "#         verbose=1,\n",
    "#         save_best_only=True\n",
    "#         )\n",
    "    print(Y_train.shape)\n",
    "    history = model.fit_generator(\n",
    "        datagen.flow(X_train, Y_train, batch_size=20),\n",
    "        epochs = epochs,\n",
    "      validation_data=(X_val,Y_val),\n",
    "      steps_per_epoch=100\n",
    "    )\n",
    "    return model\n",
    "'''\n",
    "\n",
    "x_data, y_label_data = load_data()\n",
    "x_data = resize_picture(x_data)\n",
    "model = build_model()\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "epoch = 25\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_data, y_label_data, random_state=random_seed,test_size=0.5)\n",
    "x,y = gaussian_noise(X_train,Y_train)\n",
    "X_train = np.append(X_train,x,axis=0)\n",
    "\n",
    "Y_train = np.append(Y_train,y)\n",
    "\n",
    "x,y = pepper_noise(X_train,Y_train)\n",
    "\n",
    "X_train = np.append(X_train,x,axis=0)\n",
    "Y_train = np.append(Y_train,y)\n",
    "x,y = salt_noise(X_train,Y_train)\n",
    "\n",
    "X_train = np.append(X_train,x,axis=0)\n",
    "Y_train = np.append(Y_train,y)\n",
    "history = model.fit(X_train,Y_train,batch_size=32,epochs=epoch,verbose=1,validation_data=(X_val,Y_val)).history\n",
    "plot_graph(history,epoch)\n",
    "  \n",
    "#model = fit_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# import augmentation\n",
    "from tqdm import tqdm\n",
    "# import plot_learningcurve\n",
    "\n",
    "os.environ['OPENCV_IO_ENABLE_JASPER']= '1'\n",
    "#数値に変換\n",
    "def trans_from_cup_to_int(name_value):\n",
    "    name_array = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H以上\"]\n",
    "    return name_array.index(name_value)\n",
    "\n",
    "#データの読み込み\n",
    "def load_data():\n",
    "    print(\"start loading...\")\n",
    "    path = \"data\"\n",
    "    name_list = [i for i in os.listdir(path) if i != '.DS_Store']\n",
    "    pic_num = 0\n",
    "    x_data = []\n",
    "    y_label_data = []\n",
    "    for name in name_list:\n",
    "        label_value = trans_from_cup_to_int(name)\n",
    "        pic_folder_path = path + \"/\" + name\n",
    "        pic_list = [i for i in os.listdir(pic_folder_path) if i != '.DS_Store']\n",
    "        for pic_name in tqdm(pic_list):\n",
    "            pic_path = pic_folder_path+\"/\"+pic_name\n",
    "            img = cv2.imread(pic_path)\n",
    "            x_data.append(img)\n",
    "            y_label_data.append(label_value)\n",
    "    x_data = np.array(x_data)\n",
    "    y_label_data = np.array(y_label_data)\n",
    "    print(\"loading has finished!\")\n",
    "    return x_data, y_label_data\n",
    "\n",
    "#データの大きさ揃える、とりあえず150*150で様子見\n",
    "def resize_picture(images):\n",
    "    changed_images = []\n",
    "    for img in images:\n",
    "        img = cv2.resize(img, dsize=(150, 150))\n",
    "        changed_images.append(img)\n",
    "    changed_images = np.array(changed_images)\n",
    "    return changed_images\n",
    "\n",
    "#データの切り取りによるかさまし、いらないかも\n",
    "def make_more_data(images):\n",
    "    trans_images = []\n",
    "    for image in images:\n",
    "        cut_img = img[img.shape[0]//6:img.shape[0]*5//6,img.shape[1]//6:img.shape[1]*5//6]\n",
    "        trans_images.append(cut_img)\n",
    "    images.extend(trans_images)\n",
    "    return images\n",
    "\n",
    "def build_model():\n",
    "    base_model=VGG19(weights='imagenet',include_top=False,\n",
    "                 input_tensor=Input(shape=(150,150,3)))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(30))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(30))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model = Model(input=base_model.input,output=model(base_model.output))    \n",
    "\n",
    "    for layer in base_model.layers[:15]:\n",
    "        layer.trainable=False\n",
    "\n",
    "    model.compile(Adam(lr=0.001),loss='mean_squared_error',metrics=['mae'])\n",
    "    print(\"Build model!\")\n",
    "    return model\n",
    "'''\n",
    "\n",
    "def fit_model(model):\n",
    "    samples_per_epoch = 20\n",
    "    batch_size=32\n",
    "    epochs = 10\n",
    "    #とりあえずぼかし以外\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    #ここから下はこれを参照https://lp-tech.net/articles/Y56uo\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10 , verbose=1)\n",
    "#     checkpointer = ModelCheckpoint(\n",
    "#         model_weights,\n",
    "#         monitor='val_loss',\n",
    "#         verbose=1,\n",
    "#         save_best_only=True\n",
    "#         )\n",
    "    print(Y_train.shape)\n",
    "    history = model.fit_generator(\n",
    "        datagen.flow(X_train, Y_train, batch_size=20),\n",
    "        epochs = epochs,\n",
    "      validation_data=(X_val,Y_val),\n",
    "      steps_per_epoch=100\n",
    "    )\n",
    "    return model\n",
    "'''\n",
    "\n",
    "x_data, y_label_data = load_data()\n",
    "x_data = resize_picture(x_data)\n",
    "model = build_model()\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "epoch = 25\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_data, y_label_data, random_state=random_seed,test_size=0.5)\n",
    "x,y = gaussian_noise(X_train,Y_train)\n",
    "X_train = np.append(X_train,x,axis=0)\n",
    "\n",
    "Y_train = np.append(Y_train,y)\n",
    "\n",
    "x,y = pepper_noise(X_train,Y_train)\n",
    "\n",
    "X_train = np.append(X_train,x,axis=0)\n",
    "Y_train = np.append(Y_train,y)\n",
    "x,y = salt_noise(X_train,Y_train)\n",
    "\n",
    "X_train = np.append(X_train,x,axis=0)\n",
    "Y_train = np.append(Y_train,y)\n",
    "history = model.fit(X_train,Y_train,batch_size=32,epochs=epoch,verbose=1,validation_data=(X_val,Y_val)).history\n",
    "plot_graph(history,epoch)\n",
    "  \n",
    "#model = fit_model(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
